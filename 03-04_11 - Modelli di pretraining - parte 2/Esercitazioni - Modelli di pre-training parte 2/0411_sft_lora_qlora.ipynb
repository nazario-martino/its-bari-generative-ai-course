{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Day 2 (04/11) ‚Äî Supervised Fine-Tuning, LoRA e QLoRA\n",
    "\n",
    "**Obiettivo pratico (4 ore di codice)**: Apprendere il Supervised Fine-Tuning (SFT) e metodi efficienti (LoRA, QLoRA) su dataset IMDB per sentiment analysis con DistilBERT e GPT-2.\n",
    "\n",
    "---\n",
    "\n",
    "## üó∫Ô∏è Roadmap della lezione (240 minuti di codice)\n",
    "\n",
    "| **Sezione** | **Contenuto** | **Tempo stimato** |\n",
    "|-------------|---------------|-------------------|\n",
    "| 1 | Setup e teoria SFT | 20' |\n",
    "| 2 | Preparazione dataset IMDB | 30' |\n",
    "| 3 | SFT su DistilBERT (classification) | 60' |\n",
    "| 4 | LoRA su GPT-2 | 50' |\n",
    "| 5 | QLoRA su GPT-2 | 50' |\n",
    "| 6 | Confronto base vs fine-tuned | 30' |\n",
    "| **TOTALE** | | **240'** |\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Leggi dopo (teoria fuori orario)\n",
    "\n",
    "### Supervised Fine-Tuning (SFT)\n",
    "- **Definizione**: adattare un modello pre-trained a un task specifico usando dati labeled\n",
    "- **Differenza da pre-training**: pre-training usa dati non supervisionati (next token prediction), SFT usa dati labeled (es. sentiment, QA)\n",
    "- **Vantaggi**: costi ridotti, specializzazione, performance migliori su task specifici\n",
    "- **Svantaggi**: rischio overfitting su dataset piccoli, dipendenza da qualit√† labels\n",
    "\n",
    "### LoRA (Low-Rank Adaptation)\n",
    "- **Paper**: Hu et al., 2021 - \"LoRA: Low-Rank Adaptation of Large Language Models\"\n",
    "- **Idea**: invece di aggiornare tutti i pesi W, aggiungi matrici low-rank A e B\n",
    "- **Formula**: `W' = W + BA` dove B ‚àà R^(d√ór), A ‚àà R^(r√ók), r << d\n",
    "- **Vantaggi**: riduce parametri trainable del 90-99%, memoria ridotta, training pi√π veloce\n",
    "- **Parametri chiave**:\n",
    "  - `r` (rank): dimensione bottleneck (tipicamente 4-64)\n",
    "  - `alpha`: scaling factor (tipicamente 16-32)\n",
    "  - `target_modules`: quali layer modificare (query, value, etc.)\n",
    "\n",
    "### QLoRA (Quantized LoRA)\n",
    "- **Paper**: Dettmers et al., 2023 - \"QLoRA: Efficient Finetuning of Quantized LLMs\"\n",
    "- **Idea**: combina quantizzazione (int4/int8) + LoRA\n",
    "- **Vantaggi**: riduce memoria del 75% rispetto a LoRA, permette fine-tuning di modelli grandi su GPU consumer\n",
    "- **Libreria**: `bitsandbytes` per quantizzazione\n",
    "\n",
    "### Librerie di supporto\n",
    "- **PEFT** (Parameter-Efficient Fine-Tuning): libreria Hugging Face per LoRA, QLoRA, etc.\n",
    "- **Axolotl**: framework per fine-tuning con config YAML\n",
    "- **DeepSpeed**: ottimizzazioni per training distribuito (ZeRO optimizer)\n",
    "- **Hugging Face Trainer**: API high-level per training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup e teoria SFT (20 minuti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installazione librerie\n",
    "%pip install torch transformers datasets peft bitsandbytes accelerate scikit-learn matplotlib pandas numpy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo l'installazione, se appare il messaggio che chiede di riavviare il kernel, dalla toolbar in alto selezionare **\"Kernel\"** e in seguito **\"Restart Kernel and Clear Outputs of All Cells...\"** \n",
    "\n",
    "**Attendere circa 30 secondi e in seguito NON eseguire nuovamente il blocco \"Installazione librerie\" ma procedere con il blocco successivo, \"Import librerie\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trasformers version: 4.57.1\n",
      "‚úÖ PyTorch: 2.8.0+cpu\n",
      "‚úÖ Device: cpu\n",
      "‚úÖ Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Import librerie\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    set_seed\n",
    ")\n",
    "from transformers.utils import logging as hf_logging\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"‚úÖ Trasformers version: {transformers.__version__}\")\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ Device: {device}\")\n",
    "print(f\"‚úÖ Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directory create\n"
     ]
    }
   ],
   "source": [
    "# Creazione directory\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs('./results_day2', exist_ok=True)\n",
    "os.makedirs('./models_day2', exist_ok=True)\n",
    "print(\"‚úÖ Directory create\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Teoria: SFT vs Pre-training\n",
    "\n",
    "| **Aspetto** | **Pre-training** | **Supervised Fine-Tuning (SFT)** |\n",
    "|-------------|------------------|----------------------------------|\n",
    "| **Obiettivo** | Apprendere rappresentazioni generali | Specializzare su task specifico |\n",
    "| **Dati** | Non supervisionati (testo raw) | Supervisionati (labeled) |\n",
    "| **Loss** | Next token prediction (CLM) | Task-specific (classification, QA, etc.) |\n",
    "| **Dataset size** | Miliardi di token | Migliaia/milioni di esempi |\n",
    "| **Costo** | Altissimo ($100K - $10M) | Basso ($100 - $10K) |\n",
    "| **Tempo** | Settimane/mesi | Ore/giorni |\n",
    "| **Quando usare** | Creare modello da zero | Adattare modello esistente |\n",
    "\n",
    "### Applicazioni tipiche di SFT:\n",
    "1. **Sentiment analysis**: classificare recensioni (positivo/negativo)\n",
    "2. **Question Answering**: rispondere a domande su contesto\n",
    "3. **Summarization**: riassumere documenti\n",
    "4. **Named Entity Recognition**: estrarre entit√† (persone, luoghi, etc.)\n",
    "5. **Chatbot**: generare risposte conversazionali\n",
    "\n",
    "### Limiti di SFT:\n",
    "- **Overfitting**: su dataset piccoli (<1000 esempi)\n",
    "- **Distribuzione shift**: se test set diverso da train set\n",
    "- **Bias**: eredita bias da labels umani\n",
    "- **Catastrophic forgetting**: pu√≤ dimenticare conoscenze pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Preparazione dataset IMDB (30 minuti)\n",
    "\n",
    "**IMDB** √® un dataset di recensioni di film:\n",
    "- 50,000 recensioni totali (25K train, 25K test)\n",
    "- 2 classi: positivo (1) e negativo (0)\n",
    "- Testo in inglese, lunghezza variabile\n",
    "\n",
    "Per velocit√† su CPU, useremo una versione ridotta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Caricamento dataset IMDB...\n",
      "\n",
      "‚úÖ Dataset caricato!\n",
      "   Train: 25000 esempi\n",
      "   Test: 25000 esempi\n"
     ]
    }
   ],
   "source": [
    "# Carica dataset IMDB\n",
    "print(\"‚è≥ Caricamento dataset IMDB...\")\n",
    "\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset caricato!\")\n",
    "print(f\"   Train: {len(dataset['train'])} esempi\")\n",
    "print(f\"   Test: {len(dataset['test'])} esempi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Esempio di recensione:\n",
      "\n",
      "Testo: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ev...\n",
      "\n",
      "Label: 0 (Negativo)\n"
     ]
    }
   ],
   "source": [
    "# Esplora dataset\n",
    "print(\"\\nüìä Esempio di recensione:\\n\")\n",
    "\n",
    "example = dataset['train'][0]\n",
    "print(f\"Testo: {example['text'][:200]}...\")\n",
    "print(f\"\\nLabel: {example['label']} ({'Positivo' if example['label'] == 1 else 'Negativo'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dataset ridotto:\n",
      "   Train: 2000 esempi\n",
      "   Test: 500 esempi\n"
     ]
    }
   ],
   "source": [
    "# Riduci dataset per velocit√† (CPU-friendly)\n",
    "# Usiamo 2000 train, 500 test\n",
    "\n",
    "TRAIN_SIZE = 2000\n",
    "TEST_SIZE = 500\n",
    "\n",
    "train_dataset = dataset['train'].shuffle(seed=SEED).select(range(TRAIN_SIZE))\n",
    "test_dataset = dataset['test'].shuffle(seed=SEED).select(range(TEST_SIZE))\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset ridotto:\")\n",
    "print(f\"   Train: {len(train_dataset)} esempi\")\n",
    "print(f\"   Test: {len(test_dataset)} esempi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Distribuzione classi:\n",
      "\n",
      "Train:\n",
      "   Positivo: 1000 (50.0%)\n",
      "   Negativo: 1000 (50.0%)\n",
      "\n",
      "Test:\n",
      "   Positivo: 246 (49.2%)\n",
      "   Negativo: 254 (50.8%)\n",
      "\n",
      "‚úÖ Grafico salvato in ./results_day2/class_distribution.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHNElEQVR4nO3dB5RV5bk//mekdwRR5CpIsKJYosae2AKWuCzcxBZFJeL1irHXKNiNJJZoFGN+uZZcjYmJJRovir33FnsjogHFiCCgKOX81/tmnfnPUISRmT3lfD5r7Xvm7LNnnz2s7H0fv/vdz1tVKpVKAQAAAAAFWq7ILwMAAACARCgFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFEBEHHXRQrLbaao19GAAAABVDKAU0aVVVVUu1PPDAA9HU/OMf/4iDDz44BgwYEO3bt4/evXvHd7/73Rg9evQ32t+dd94ZZ5xxRr0fJwDQshRZP33++ee5PqnLvtRIQFlVqVQqVb8DaGL+93//t9b76667LsaPHx+///3va63//ve/HyuttNI3/p45c+bE/Pnzo127dlEf3n777dh0002jQ4cOccghh+RRWJMnT47nnnsu/u///i9mz55d532OHDkyLr/88nDZBgCaQv2U/Otf/4pevXrlQGlpgiE1ElBT61rvAJqYH//4x7XeP/HEE7moWnD9ou7adezYcam/p02bNlGfLr744pg5c2a88MIL0a9fv1qfTZkypV6/CwCgPuqnIqiRgJo8vgc0e9tuu22st9568eyzz+ah3ymMOvXUU/Nnt912W+y6667Rp0+fPAoqDRM/++yzY968eV/bUyoNK0/D2n/5y1/GVVddlX8v/X66s/f0008v8ZjeeeedWGWVVRYqtpIVV1xxoXXpzuA222wTnTp1ii5duuRjfuWVV2odX7oDmNQcdg8A8E2kEeKXXHJJrLvuuvkRujRi6rDDDotPP/201nbPPPNMDBkyJFZYYYU8uql///55hFO5XkqjpJIzzzyzuj75uhFTaiSgJiOlgBbhk08+iZ133jn22WeffBewPBT9mmuuic6dO8exxx6bX++7774YNWpUfPbZZ/GLX/xiifu94YYbYsaMGblISwXOmDFjYq+99op33333a0dXpULrnnvuyd+3/fbbf+13pKH0w4YNywXfBRdckEd5jR07Nrbeeut4/vnnc1iWvn/SpEmLHHoPAFBXqbZIdVLq7fTTn/40JkyYEL/+9a9z7fHoo4/mOieNXBo8eHAOnk4++eTo3r17DqJuvvnmvI+0PtUshx9+eOy55565RkrWX3/9xX6vGgmoJfWUAmgujjjiiNQsoNa6733ve3ndlVdeudD2n3/++ULrDjvssFLHjh1Ls2fPrl43bNiwUr9+/arfT5gwIe+zZ8+epalTp1avv+222/L622+//WuP8+WXXy516NAhb7vhhhuWjjrqqNKtt95amjVrVq3tZsyYUerevXvp0EMPrbX+ww8/LHXr1q3W+kX97QAAS7JgDfHwww/n99dff32t7caNG1dr/S233JLfP/3004vd98cff5y3GT169FIdixoJqMnje0CLkB6tS3f6FpSGmZelEU+pGWcaAp7utL3++utL3O/ee+8dyy+/fPX79LtJGin1ddJQ+NQrIY3aSncUf/WrX8Uee+yRR3D99re/rd4u3dWbNm1a7LvvvvnYykurVq1is802i/vvv3+p/w0AAJbGTTfdFN26dcuNzmvWHxtvvHEeWV6uP9LIqOSOO+7Ik8LUBzUSUJPH94AW4T/+4z+ibdu2C61PPQdOO+20PEQ8PbJX0/Tp05e43759+9Z6Xw6oFuy3sChrrrlmHkae+le9+uqruaBLj/+NGDEi92PYcccd46233srbLm74eteuXZf4PQAAdZHqj1QHLaqHU82G49/73vdi6NChuV9UalCe+nimAGm//fZbphmL1UhAmVAKaBFqjogqS3fXUjGVipazzjorNytPjTzTlMMnnXRSbvC5JOlu3KLUZcrhtI9BgwblZYsttojtttsurr/++lxwlY8hFWa9e/de6Hdbt3aZBgDqV6o/UiCV6pFFKTcvT/00//znP+fZ+26//fa46667cpPzCy+8MK9Lo6qWhRoJcCYDLdYDDzyQG6CnZpxpVr6y1MizsWyyySb5dfLkyfk1BWVJKgxTAfZ1zCQDANSHVH+kZuNbbbXVIm/sLWjzzTfPy7nnnpsngdl///3jxhtvjJ/85Cf1Vp+okaAy6SkFtFjlUU41RzV99dVXccUVVzT4dz/88MOL7L1w55135te11lorv6bZZNJIrvPOO2+R23/88cfVP6epkMsjwAAAvqkf/ehH+dG5s88+e6HP5s6dW11rpHYFC44O33DDDfPrl19+mV87duxYp/pEjQTUZKQU0GJtueWWuQdUmko4TXWc7qKlIeB1efTum0rTFj/77LN5auTytMjpscHrrrsuevToEUcffXRel4qtNLXxAQccEN/+9rdjn332yUPmJ06cGH/729/yHcw0PXOSmo8m6W9JhVoK3dL2AAB1kdobHHbYYXH++efnpuODBw+ONm3a5D5OqQl6aj7+n//5n3Httdfmm3l77rlnHrmUJo1JzchT/bLLLrvkfaWRVgMHDow//vGPuVdUqnPWW2+9vCyKGgmopdZcfABN3KKm/P3e975XWnfddRe5/aOPPlrafPPN89TDffr0KZ144omlu+66K+/j/vvvr95u2LBhpX79+lW/nzBhQt7mF7/4xUL7XJppj9P3pmNdb7318rTFbdq0KfXt27d00EEHld55552Ftk/HMmTIkLxt+/btSwMGDMjbPvPMM9XbzJ07t3TkkUeWevXqVaqqqjL1MQDwjeun5KqrriptvPHGuU7q0qVLadCgQblWmjRpUv78ueeeK+277765hmnXrl1pxRVXLP3gBz+oVZ8kjz32WN5P27Ztl1gnqZGAmqrS/6kdUwEAAABAw9JTCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKFzr4r+y+Zk/f35MmjQpunTpElVVVY19OABAIyqVSjFjxozo06dPLLec+3s1qZkAgLrUS0KppZCKq1VXXbWxDwMAaELef//9WGWVVRr7MJoUNRMAUJd6SSi1FNLdvvI/ZteuXRv7cACARvTZZ5/l4KVcH/D/UzMBAHWpl4RSS6E8/DwVVwosACDxeNrC1EwAQF3qJY0QAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAAKisUOqhhx6K3XbbLfr06RNVVVVx66231vq8VCrFqFGjYuWVV44OHTrEjjvuGG+99VatbaZOnRr7779/dO3aNbp37x7Dhw+PmTNn1trmpZdeim222Sbat28fq666aowZM6aQvw8AAACAJhhKzZo1KzbYYIO4/PLLF/l5Co8uvfTSuPLKK+PJJ5+MTp06xZAhQ2L27NnV26RA6pVXXonx48fHHXfckYOuESNGVH/+2WefxeDBg6Nfv37x7LPPxi9+8Ys444wz4qqrrirkbwQAAABgYVWlNBypCUgjpW655ZbYY4898vt0WGkE1XHHHRfHH398Xjd9+vRYaaWV4pprrol99tknXnvttRg4cGA8/fTTsckmm+Rtxo0bF7vsskt88MEH+ffHjh0bP/vZz+LDDz+Mtm3b5m1OPvnkPCrr9ddfX6pjS8FWt27d8venEVkAQOVSFyyefxsAoC41QZPtKTVhwoQcJKVH9srSH7TZZpvF448/nt+n1/TIXjmQStL2yy23XB5ZVd7mu9/9bnUglaTRVm+88UZ8+umnhf5NAAAAAPxb62iiUiCVpJFRNaX35c/S64orrljr89atW0ePHj1qbdO/f/+F9lH+bPnll1/ou7/88su81Ez4kvnz5+elIfzrX/+q/h6g7lL6vsIKK0RL4ZoATfea0FC1AEv28ccfuzbCMl4be/Xq1diHAdD0Q6nGdP7558eZZ565yEKoZj+r+pKGs11+8UUxZ9aset83VIo2nTrFEcccm0dUNnfpmnDRry+JmV990diHAs1W57Yd4tiRRzfINWHGjBn1vk+WLNVhhx14QMyePq2xDwWarfbdusdvrvu9YApoMppsKNW7d+/8+tFHH+XZ98rS+w033LB6mylTptT6vblz5+YZ+cq/n17T79RUfl/eZkGnnHJKHHvssdXv0x25NGtfung3RH+ENFvgO39/KQ5bq3/8R7cu9b5/aOn+OX1G/ObvL0WrVq0WGj3ZHKVrwotvvxp9fvyd6LLSwqM5ga8346NP453/farBrglpNt+meEPt5ptvzv0y04zFW265ZVxwwQWx1lprVW+z7bbbxoMPPljr9w477LA8oUzZxIkT4/DDD4/7778/OnfuHMOGDcv7TiPRG1uqx1Igdbh6Cb5xvTT2jQn5XBJKAU1F41cYi5EeuUuh0b333lsdQqULaOoVlYqlZIsttohp06blWfU23njjvO6+++7Lw+pT76nyNqnR+Zw5c6JNmzZ5XZqpLxVpi3p0L2nXrl1eFpR6VaWlIZq8p8buq3TtHP2X717v+4eWrqpUyudQOpca4hwtWvma0Ln38tG1X/MP2aBopapo0GtCU7zOpLDpiCOOiE033TTfoDv11FPz7MOvvvpqnr247NBDD42zzjqr+n3Hjh2rf543b17suuuuuf567LHHYvLkyXHggQfm+um8886LpiIFUv17COwBoCVo3dijAd5+++1azc1feOGF3BOqb9++cfTRR8c555wTa6yxRg6pTj/99DyjXnmGvnXWWSd22mmnXGClu3wpeBo5cmSemS9tl+y33375Ubzhw4fHSSedFC+//HL86le/iosvvrjR/m4AgPqUZh+uKc1UnEaJpRt3acKXmiHU4kaK33333TnEuueee3L/zXRT8Oyzz8710xlnnFFr0hgAgPrQqLf6nnnmmdhoo43ykqRH5tLPo0aNyu9PPPHEOPLII2PEiBH5zl8KsVLRVXPY/PXXXx9rr7127LDDDrHLLrvE1ltvHVdddVX156mXRCqyUuCVRlMdd9xxef9pnwAALVHqTZekG301pbopNYBfb731cruCzz//vPqzNGPxoEGDak0yk2YsTiPVX3nllQKPHgCoFI06Uir1NkjD6xcnDbtPQ8xrDjNfUCq2brjhhq/9nvXXXz8efvjhZTpWAIDmILUxSKPNt9pqqxw+laXR4/369cujyV966aU8AuqNN97IvajKsxIvatbj8meLUuSMxeVHMktpqdc9Q2VI5065RYBZRIGGtrTXmSbbUwoAgLpLvaVSu4JHHnmk1vqao8TTiKg0kUwaaf7OO+/EgAEDmvyMxWnWw77fGhCze/SKqV061+u+oRLMrmqTz6F0Li04WRRAY81WLJQCAGghUm/NO+64Ix566KFYZZVVvnbb8qQwqb9nCqVSr6mnnnqqyc5YnNo4THz3nWi/QqfoUZpTr/uGSjD902n5HOrSpUuLmK0YaNqWdrZioRQAQDOXHsdJfThvueWWeOCBB/IEMUuSJpdJ0oip8ozF5557bh5BUf4P1jRjcQqXBg4c2OgzFpcfO0ozrlbV656hMrS02YqBpm1przNCKQCAFvDIXuqxedttt+VREOUeUGnClw4dOuRH9NLnaVKYnj175p5SxxxzTJ6ZL/XeTAYPHpzDpwMOOCDGjBmT93HaaaflfS8qeAIAWFYicgCAZm7s2LF5xr00iUwa+VRe/vjHP+bP27ZtG/fcc08OntKsxWk24qFDh8btt99evY9WrVrlR//Saxo19eMf/zgOPPDAr51wBgBgWRgpBQDQzH3dbMZJ6vP04IMPLnE/aXa+O++8sx6PDKDhpEkVyrN+AnWXHtFPfSAbk1AKAACAZhdIHTDioPj0i6Wb4QtY2PIdusTvr7qmUYMpoRQAAADNShohlQKpPgdsFl16L9/YhwPNzowPP41Jv38yn0tCKQAAAKijFEh16/fvGUOB5kejcwAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAKJ5QCAAAAoHBCKQAAAAAK16RDqXnz5sXpp58e/fv3jw4dOsSAAQPi7LPPjlKpVL1N+nnUqFGx8sor52123HHHeOutt2rtZ+rUqbH//vtH165do3v37jF8+PCYOXNmI/xFAAAAADT5UOqCCy6IsWPHxq9//et47bXX8vsxY8bEZZddVr1Nen/ppZfGlVdeGU8++WR06tQphgwZErNnz67eJgVSr7zySowfPz7uuOOOeOihh2LEiBGN9FcBAAAA0DqasMceeyx233332HXXXfP71VZbLf7whz/EU089VT1K6pJLLonTTjstb5dcd911sdJKK8Wtt94a++yzTw6zxo0bF08//XRssskmeZsUau2yyy7xy1/+Mvr06dOIfyEAAABAZWrSodSWW24ZV111Vbz55pux5pprxosvvhiPPPJIXHTRRfnzCRMmxIcffpgf2Svr1q1bbLbZZvH444/nUCq9pkf2yoFUkrZfbrnl8siqPffcc6Hv/fLLL/NS9tlnn+XX+fPn56W+pXCtqqoqSmmp971Dy5fOnXwOlUoNco4WrXxNqCpFXoC6yedOA14TWsJ1BgCgKWjSodTJJ5+cA6G11147WrVqlXtMnXvuuflxvCQFUkkaGVVTel/+LL2uuOKKtT5v3bp19OjRo3qbBZ1//vlx5plnLrT+448/rvVYYH2ZMWNG9P3WgJjdo1dM7dK53vcPLd3sqjb5HErn0pQpU6K5S3/HgL79o/e8ztFxZtvGPhxodjrM6xxz+/ZvsGtC2i8AAC08lPrTn/4U119/fdxwww2x7rrrxgsvvBBHH310fuRu2LBhDfa9p5xyShx77LHV71Mwtuqqq0avXr1ys/T6lpquT3z3nWi/QqfoUZpT7/uHlm76p9PyOdSlS5eFQujmKF0T3pk4IVq3WjO6de7Y2IcDzc70T/59DjXUNaF9+/bR1KQbajfffHO8/vrreeKXNNo89eJca621qrdJN9aOO+64uPHGG/OI8NSD84orrqh1c2/ixIlx+OGHx/333x+dO3fO9Vbad7qhBwBQ35p0hXHCCSfk0VLpMbxk0KBB8d577+XiKBVJvXv3zus/+uijPPteWXq/4YYb5p/TNgveJZ07d26eka/8+wtq165dXhaUHvlLS30rP2JQlZZ63zu0fOncKT/y1hDnaNHK14RSVXo0sbGPBpqffO404DWhKV5nHnzwwTjiiCNi0003zXXOqaeeGoMHD45XX301TwKTHHPMMfG3v/0tbrrpptzuYOTIkbHXXnvFo48+mj9PI9JTH89UH6W+npMnT44DDzww2rRpE+edd14j/4UAQEvU9KqqGj7//POFCr/0GF+5l0P//v1z4XTvvffWGtWUekVtscUW+X16nTZtWjz77LPV29x33315H6n3FABAc5cmdTnooIPyyPINNtggrrnmmjzqqVz/TJ8+PX73u9/lvpzbb799bLzxxnH11Vfn8OmJJ57I29x99905xPrf//3ffHNv5513jrPPPjsuv/zy+Oqrrxr5LwQAWqImPVJqt912yz2k+vbtm4us559/PhdThxxySP483QFNj/Odc845scYaa+SQ6vTTT8+P9+2xxx55m3XWWSd22mmnOPTQQ+PKK6+MOXPm5DuDafSVmfcAgJYohVBJ6qGZpHAq1UA1J4dJPTtTjZUmhdl8883zaxqVXvNxvvSIX3qc75VXXomNNtqoUSeHMTEMLBsTwwBNcWKYJh1KXXbZZTlk+u///u/8CF4KkQ477LAYNWpU9TYnnnhizJo1K0aMGJFHRG299db5bmHNfg+pL1UKonbYYYc88mro0KFx6aWXNtJfBQDQcFIRmG7abbXVVrHeeuvldWlyl7Zt2+YZib9ucphFTR5T/qyxJ4cxMQwsGxPDAE1xYpgmHUqlBqWXXHJJXhYnJXtnnXVWXhYn3SVMzdIBAFq61Fvq5ZdfjkceeaTBv6vIyWFMDAPLxsQwQFOcGKZJh1IAACy9NDL8jjvuiIceeihWWWWV6vWpB2fqC5VGldccLZUmhylP/JJen3rqqVr7S5+XP2vsyWFMDAPLxsQwQFOcGKb5X40AACpcKipTIHXLLbfkCV1Sn82aUmPzNItezclh3njjjdwMvebkMH//+99rDeEfP358HvE0cODAAv8aAKBSGCkFANACHtlLrQpuu+22PAy/3AOqW7du0aFDh/w6fPjw/KhdamuQgqYjjzwyB1GpyXkyePDgHD4dcMABMWbMmLyP0047Le97UaOhAACWlVAKAKCZGzt2bH7ddttta62/+uqr46CDDso/X3zxxdUTvqQZ89LMeldccUX1tq1atcqP/qXZ9lJY1alTpxg2bNjX9u0EAFgWQikAgBbw+N7SNBy9/PLL87I4/fr1izvvvLOejw4AYNH0lAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAArXemk2OvbYY+Pss8+OTp065Z+/zkUXXVRfxwYA0KKoqQAA6hhKPf/88zFnzpzqnxenqqpqaXYHAFCR1FQAAHUMpe6///5F/gwAwNJTUwEA1FNPqffffz8vAAB8c2oqAKAS1TmUmjt3bpx++unRrVu3WG211fKSfj7ttNOqh6MDAPD11FQAQKVbqsf3ajryyCPj5ptvjjFjxsQWW2yR1z3++ONxxhlnxCeffBJjx45tiOMEAGhR1FQAQKWrcyh1ww03xI033hg777xz9br1118/Vl111dh3330VUAAAS0FNBQBUujo/vteuXbs8vHxB/fv3j7Zt29bXcQEAtGhqKgCg0tU5lBo5cmScffbZ8eWXX1avSz+fe+65+TMAAJZMTQUAVLo6P773/PPPx7333hurrLJKbLDBBnndiy++GF999VXssMMOsddee1Vvm/okAACwMDUVAFDp6hxKde/ePYYOHVprXep9AADA0lNTAQCVrs6h1NVXX90wRwIAUEHUVABApatzTykAAAAAKHyk1CeffBKjRo2K+++/P6ZMmRLz58+v9fnUqVOX+aAAAFo6NRUAUOnqHEodcMAB8fbbb8fw4cNjpZVWiqqqqoY5MgCAFkxNBQBUujqHUg8//HA88sgj1bPEAABQd2oqAKDS1bmn1Nprrx1ffPFFwxwNAECFUFMBAJWuzqHUFVdcET/72c/iwQcfzL0QPvvss1oLAABLpqYCACpdnR/f6969ey6Utt9++1rrS6VS7oUwb968+jw+AIAWSU0FAFS6OodS+++/f7Rp0yZuuOGGQppy/vOf/4yTTjop/u///i8+//zzWH311ePqq6+OTTbZpLpwGz16dPz2t7+NadOmxVZbbRVjx46NNdZYo9bsNUceeWTcfvvtsdxyy8XQoUPjV7/6VXTu3LlBjx0AoKnUVAAAzT6Uevnll+P555+PtdZaKxrap59+mkOm7bbbLodSvXr1irfeeiuWX3756m3GjBkTl156aVx77bXRv3//OP3002PIkCHx6quvRvv27auLvsmTJ8f48eNjzpw5cfDBB8eIESNyEQgA0BiKrKkAAFpEKJVGKL3//vuFFFAXXHBBrLrqqnlkVFkKnsrSKKlLLrkkTjvttNh9993zuuuuuy7fbbz11ltjn332iddeey3GjRsXTz/9dPXoqssuuyx22WWX+OUvfxl9+vRp8L8DAKAxayoAgBbR6Dw9BnfUUUfFNddcE88++2y89NJLtZb69Ne//jUXbD/84Q9jxRVXjI022ig/plc2YcKE+PDDD2PHHXesXtetW7fYbLPN4vHHH8/v02vq2VAOpJK0fXqM78knn1zk93755ZeLbDY6f/78BlnKvSNKaUlhm8ViqdtSVfXvc6hUarDztMilfE2oKoXFYvmmSwNfE+pDfdZUDz30UOy22275Zlv629PNuZoOOuigf19Xaiw77bRTrW1Su4M0urxr1665dho+fHjMnDmzXv5WAIB6GSm1995759dDDjmkel258Kvvppzvvvtu7g917LHHxqmnnppHO/30pz+Ntm3bxrBhw3IglaSRUTWl9+XP0msKtGpq3bp19OjRo3qbBZ1//vlx5plnLrT+448/jtmzZ0d9mzFjRvT91oCY3aNXTO2izxXU1eyqNvkcSufSlClTorlLf8eAvv2j97zO0XFm28Y+HGh2OszrHHP79m+wa0Lab32oz5pq1qxZscEGG+R97bXXXovcJoVQNUeft2vXrtbn2h0AAE0+lEqjk4qS7kSmEU7nnXdefp9GSqX+C1deeWUOpRrKKaeckoOwsjRSKj1GmHpapbuH9S3dhZz47jvRfoVO0aM0p973Dy3d9E+n5XOoS5cuC4XQzVG6JrwzcUK0brVmdOvcsbEPB5qd6Z/8+xxqqGtCuWflsqrPmmrnnXfOy9dJIVTv3r0X+Zl2BwBAswil+vXrF0VZeeWVY+DAgbXWrbPOOvGXv/wl/1wurD766KO8bVl6v+GGG1Zvs+Bd0rlz5+Yh6osrzFLRtuDdwyQ98peW+lZ9VzQt9b53aPnSuVMeWdAQ52jRyteEUlV6NLGxjwaan3zuNOA1ob72WWRNlTzwwAM5pEsTxmy//fZxzjnnRM+ePZeq3cGee+5Z6LECAJXhG1VVv//97/OseOmu2XvvvZfXpYbjt912W70eXPqON954o9a6N998s7qIS03PU7B077331hrVlIqnLbbYIr9Pr9OmTcu9Gsruu+++PAor9Z4CAGgsRdVU6dG9NBlMqpnSRDIPPvhgHllVfkTwm7Q7KLoPpx6cFssyLnpwWiyWUtPrwVnnkVKpx9OoUaPi6KOPjnPPPbe6mEl311IRVZ4Frz4cc8wxseWWW+bH9370ox/FU089FVdddVVekvQPmI4j3elbY401ckh1+umn58Jujz32qB5ZlQqxQw89ND/2l3okjBw5Ms/MZyg6ANBYiqypUt1TNmjQoFh//fVjwIABefTUDjvs8I33W2QfTj04YdnowQk0xR6cdQ6lUn+BNANeCn1+/vOfV69Pw72PP/74qE+bbrpp3HLLLbnH01lnnZVDp1SkpUacZSeeeGJu7pkacaYRUVtvvXXuiVCz38P111+fg6hUdKVh6EOHDo1LL720Xo8VAKCp1lQL+ta3vhUrrLBCvP3227k++ibtDoruw6kHJywbPTiBptiD8xs1Ok8NxxeUejClcKi+/eAHP8jL4qTRUimwSsvipKHnZo4BAJqSomuqmj744IP45JNPqnty1mx3sPHGGy91u4Mi+3DqwQnLRg9OoCn24KzzN6fRSi+88MJC69PopPSoHAAAxdZUacRA2ld5fynwSj9PnDgxf3bCCSfEE088Ef/4xz9yX6n0aODqq68eQ4YMWajdQWqX8Oijj2p3AAA0uDqPlEpDtI844ojcJyClaqlw+cMf/pB7Cvy///f/GuYoAQBamPqsqZ555pnYbrvtau07GTZsWO5d9dJLL8W1116bR0OlkGnw4MFx9tln1xrlpN0BANDkQ6mf/OQn0aFDhzjttNPi888/j/322y8XN7/61a9qNdEEAKCYmmrbbbfNwdbi3HXXXUvch3YHAECTD6WS1Gg8LamASkPCW0KjPACAoqmpAIBKVueeUl988UUunJKOHTvm92lGvLvvvrshjg8AoEVSUwEAla7OoVRqjHndddfln1Nfgu985ztx4YUX5vWpZwEAAEumpgIAKl2dQ6nnnnsuttlmm/zzn//85+jdu3e89957uajSDBMAYOmoqQCASlfnUCoNM+/SpUv+OQ0v32uvvfIMLZtvvnkupAAAWDI1FQBQ6eocSq2++upx6623xvvvv59ncklTCidTpkyJrl27NsQxAgC0OGoqAKDS1TmUGjVqVBx//PGx2mqr5d4HW2yxRfUdvo022qghjhEAoMVRUwEAla51XX/hP//zP2PrrbeOyZMnxwYbbFC9focddog999yzvo8PAKBFUlMBAJWuziOlktSIM/VAGD9+fJ6+ONl0001j7bXXru/jAwBosdRUAEAlq3Mo9cknn+Q7eGuuuWbssssu+e5eMnz48DjuuOMa4hgBAFocNRUAUOnqHEodc8wx0aZNm5g4cWJ07Nixev3ee+8d48aNq+/jAwBokdRUAEClq3NPqdR8M80Qs8oqq9Rav8Yaa5i+GABgKampAIBKV+eRUrNmzap1N69s6tSp0a5du/o6LgCAFk1NBQBUujqHUttss01cd9111e+rqqpi/vz5MWbMmNhuu+3q+/gAAFokNRUAUOnq/PheKpRSU85nnnkmvvrqqzjxxBPjlVdeyXf1Hn300YY5SgCAFkZNBQBUujqPlFpvvfXizTffjK233jp23333PPR8r732iueffz4GDBjQMEcJANDCqKkAgEpX55FSSbdu3eJnP/tZ/R8NAEAFUVMBAJWsziOlAAAAAGBZCaUAAAAAKJxQCgAAAIDCCaUAAAAAaB6NzpOPP/443njjjfzzWmutFb169arP4wIAqAhqKgCgUtV5pFSarviQQw6JPn36xHe/+928pJ+HDx8en3/+ecMcJQBAC6OmAgAqXZ1DqWOPPTYefPDB+Otf/xrTpk3Ly2233ZbXHXfccQ1zlAAALYyaCgCodHV+fO8vf/lL/PnPf45tt922et0uu+wSHTp0iB/96EcxduzY+j5GAIAWR00FAFS6Oo+USsPJV1pppYXWr7jiioaaAwAsJTUVAFDp6hxKbbHFFjF69OiYPXt29bovvvgizjzzzPwZAABLpqYCACpdnR/fu+SSS2KnnXaKVVZZJTbYYIO87sUXX4z27dvHXXfd1RDHCADQ4qipAIBKV+dQatCgQfHWW2/F9ddfH6+//npet++++8b++++feyAAALBkaioAoNLVKZSaM2dOrL322nHHHXfEoYce2nBHBQDQgqmpAADq2FOqTZs2tfoeAABQd2oqAIBv0Oj8iCOOiAsuuCDmzp3bMEcEAFAB1FQAQKWrc0+pp59+Ou699964++67cy+ETp061fr85ptvrs/jAwBokdRUAEClq3Mo1b179xg6dGjDHA0AQIVQUwEAla7OodTVV1/dMEcCAFBB1FQAQKWrc0+pJPU+uOeee+I3v/lNzJgxI6+bNGlSzJw5s76PDwCgxVJTAQCVrM4jpd57773YaaedYuLEifHll1/G97///ejSpUtu1JneX3nllQ1zpAAALYiaCgCodHUeKXXUUUfFJptsEp9++ml06NChev2ee+6Zm3UCALBkaioAoNLVeaTUww8/HI899li0bdu21vrVVlst/vnPf9bnsQEAtFhqKgCg0tV5pNT8+fNj3rx5C63/4IMP8pBzAACWTE0FAFS6OodSgwcPjksuuaT6fVVVVW7GOXr06Nhll13q+/gAAFokNRUAUOnq/PjehRdeGEOGDImBAwfG7NmzY7/99ou33norVlhhhfjDH/7QMEcJANDCqKkAgEpX51BqlVVWiRdffDFuvPHGeOmll/IdveHDh8f+++9fq0knAACLp6YCACpd62/0S61bx49//OP6PxoAgAqipgIAKtk3CqUmTZoUjzzySEyZMiU36azppz/9aX0dGwBAi6amAgAqWZ1DqWuuuSYOO+ywPH1xz549c1POsvSzAgoAYMnUVABApatzKHX66afHqFGj4pRTTonllqvz5H0AAKipAACizhXQ559/Hvvss4/iCQBgGaipAIBKV+cqKM0Kc9NNNzXM0QAAVAg1FQBQ6er8+N75558fP/jBD2LcuHExaNCgaNOmTa3PL7roovo8PgCAFklNBQBUum8USt11112x1lpr5fcLNuUEAGDJ1FQAQKWrcyh14YUXxv/8z//EQQcd1DBHBABQAdRUAEClq3NPqXbt2sVWW23VMEcDAFAh1FQAQKWrcyh11FFHxWWXXdYwRwMAUCHUVABApavz43tPPfVU3HfffXHHHXfEuuuuu1BTzptvvrk+jw8AoEVSUwEAla7OoVT37t1jr732apijAQCoEGoqAKDS1TmUuvrqqxvmSAAAKoiaCgCodHXuKQUAAAAAhY+U6t+/f1RVVS3283fffXdZjwkAoMVTUwEAla7OodTRRx9d6/2cOXPi+eefj3HjxsUJJ5xQn8cGANBiqakAgErX+ptMX7wol19+eTzzzDP1cUwAAC2emgoAqHT11lNq5513jr/85S/1tTsAgIqkpgIAKkW9hVJ//vOfo0ePHvW1OwCAiqSmAgAqRZ0f39too41qNeUslUrx4YcfxscffxxXXHFFfR8fAECLpKYCACpdnUOpPfbYo9b75ZZbLnr16hXbbrttrL322vV5bAAALZaaCgCodHUOpUaPHt0wRwIAUEHUVABApau3nlJF+PnPf56HudecQnn27NlxxBFHRM+ePaNz584xdOjQ+Oijj2r93sSJE2PXXXeNjh07xoorrpinWZ47d24j/AUAAAAA1GmkVBpSXrPvwaKkzxsq7Hn66afjN7/5Tay//vq11h9zzDHxt7/9LW666abo1q1bjBw5Mvbaa6949NFH8+fz5s3LgVTv3r3jsccei8mTJ8eBBx4Ybdq0ifPOO69BjhUAoKnWVAAAzS6UuuWWWxb72eOPPx6XXnppzJ8/PxrCzJkzY//994/f/va3cc4551Svnz59evzud7+LG264Ibbffvu87uqrr4511lknnnjiidh8883j7rvvjldffTXuueeeWGmllWLDDTeMs88+O0466aQ444wzom3btg1yzAAATa2mAgBolo/v7b777gstqQnnNddcE7/85S/jhz/8YbzxxhsNcpDp8bw02mnHHXestf7ZZ5+NOXPm1Fqfjqlv3765qEvS66BBg3IgVTZkyJD47LPP4pVXXmmQ4wUAKLKmeuihh2K33XaLPn365FFWt956a63P08x+o0aNipVXXjk6dOiQa6e33nqr1jZTp07NNwG7du0a3bt3j+HDh+cbgwAATabReTJp0qTcnPPaa6/NAc8LL7wQ6623Xv0fXUTceOON8dxzz+XH9xaUpk1OI51S4VRTCqDSZ+VtagZS5c/Lny3Kl19+mZeyFGAl6a5lQ9y5TIViKiBLaan3vUPLl86dfA6VSi1idEH5mlBVirwAdZPPnQa8JtTnPuurppo1a1ZssMEGccghh+Q2BgsaM2ZMHoGVvqd///5x+umn5+9Lo8nbt2+ft0mBVGpzMH78+HzT7+CDD44RI0bkEekAAI0eSqXH5VIfpssuuyw/BnfvvffGNttsEw3l/fffj6OOOioXR+WCqQjnn39+nHnmmQut//jjj3Nj9fo2Y8aM6PutATG7R6+Y2qVzve8fWrrZVW3yOZTOpSlTpkRzl/6OAX37R+95naPjTI8YQ111mNc55vbt32DXhLTfZVXfNdXOO++cl0VJ4dwll1wSp512Wh6VlVx33XX5Jl0aUbXPPvvEa6+9FuPGjcs3ATfZZJO8TTq2XXbZJY/eSiOwAAAaLZRKd9guuOCC3DD8D3/4Q3VR05DS43mpmPz2t79dvS41Lk9D1H/961/HXXfdFV999VVMmzat1mipNPteOs4kvT711FO19luena+8zYJOOeWUOPbYY2uNlFp11VWjV69eeUh7fUtD4ye++060X6FT9CjNqff9Q0s3/dNp+Rzq0qVLnmGzuUvXhHcmTojWrdaMbp07NvbhQLMz/ZN/n0MNdU1Y1htlRddUEyZMyKPDa7Y7SJPDbLbZZrnNQQql0muqpcqBVJK2T03Zn3zyydhzzz0bfXS5keWwbIwsB5riyPKlDqVOPvnk3INg9dVXz0O/07IoN998c9SXHXbYIf7+97/XWpeGkqe+C6lReQqK0ix66e7i0KFD8+epB8PEiRNjiy22yO/T67nnnpvDrXJhmkZepXBp4MCBi/zedu3a5WVBqTBLS30r/w+hKi31vndo+dK5Uy5MGuIcLVr5mlCqSgVkYx8NND/53GnAa8Ky7rPomqrcrmBR7QxqtjtYMMBr3bp19OjRY7HtDooeXW5kOSwbI8uBpjiyfKlDqQMPPHCJ0xfXt3SHc8G+Cp06dYqePXtWr09NONOoplQ0paDpyCOPzEFUmnkvGTx4cA6fDjjggHxnMhVWafh6ap6+qOAJAKAhNUZN1VCKHF1uZDksGyPLgaY4snypQ6k0I0xTdPHFF+c7lmmkVBo+npp2XnHFFdWft2rVKu644444/PDDc1iVQq1hw4bFWWed1ajHDQBUpqJrqnK7gtS+IM2+V5bep35W5W0WvEs6d+7cPCPf4todFD263MhyWDZGlgNNcWT5N5p9rzE98MADC6Vvl19+eV4Wp1+/fnHnnXcWcHQAAE1Lmm0vBUup3UE5hEojmlKvqHTTLkk37lKPztTPc+ONN87r7rvvvtwPIvWeAgBoCM0ulAIAYOHHWN5+++1azc1feOGF3N6gb9++cfTRR8c555wTa6yxRg6pTj/99Dyj3h577JG3X2eddWKnnXaKQw89NK688sqYM2dOjBw5MjdBN/MeANBQhFIAAM3cM888E9ttt131+3Kfp9SyID0ueOKJJ8asWbNixIgReUTU1ltvHePGjavV7+H666/PQVSaaKbcGuHSSy9tlL8HAKgMQikAgGZu2223zX0hFif1i0j9NL+up2YaVXXDDTc00BECACys+Xe4AwAAAKDZEUoBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFE0oBAAAAUDihFAAAAACFa9Kh1Pnnnx+bbrppdOnSJVZcccXYY4894o033qi1zezZs+OII46Inj17RufOnWPo0KHx0Ucf1dpm4sSJseuuu0bHjh3zfk444YSYO3duwX8NAAAAAM0ilHrwwQdz4PTEE0/E+PHjY86cOTF48OCYNWtW9TbHHHNM3H777XHTTTfl7SdNmhR77bVX9efz5s3LgdRXX30Vjz32WFx77bVxzTXXxKhRoxrprwIAKNYZZ5wRVVVVtZa11167Tjf5AADqW+towsaNG1frfQqT0kinZ599Nr773e/G9OnT43e/+13ccMMNsf322+dtrr766lhnnXVykLX55pvH3XffHa+++mrcc889sdJKK8WGG24YZ599dpx00km5QGvbtm0j/XUAAMVZd911cz1U1rp161o3+f72t7/lm3zdunWLkSNH5pt8jz76aCMdLQBQCZr0SKkFpRAq6dGjR35N4VQaPbXjjjtWb5Pu+vXt2zcef/zx/D69Dho0KAdSZUOGDInPPvssXnnllcL/BgCAxpBCqN69e1cvK6ywQl5fvsl30UUX5Zt8G2+8cb7Jl0aYp5t8AAAVOVKqpvnz58fRRx8dW221Vay33np53YcffphHOnXv3r3WtimASp+Vt6kZSJU/L3+2KF9++WVeylKAVT6GtNS3UqmUh9GX0lLve4eWL507+RwqlRrkHC1a+ZpQVYq8AHWTz50GvCY01+vMW2+9FX369In27dvHFltskXt3pht5S7rJl0aeAwBUdCiV+hy8/PLL8cgjjzT4d6Ui7cwzz1xo/ccff5x7LtS3GTNmRN9vDYjZPXrF1C6d633/0NLNrmqTz6F0Lk2ZMiWau/R3DOjbP3rP6xwdZ3rEGOqqw7zOMbdv/wa7JqT9NjebbbZZboOw1lprxeTJk3Ods8022+Taamlu8i1OkTfy3MSDZeMmHtAUb+I1i1Aq9TW444474qGHHopVVlmlen0aep4amE+bNq1WIZUac6bPyts89dRTtfZXbtxZ3mZBp5xyShx77LG1CqxVV101evXqFV27dq33v2/mzJkx8d13ov0KnaJHaU697x9auumfTsvnUHmmzuYuXRPemTghWrdaM7p17tjYhwPNzvRP/n0ONdQ1IY00am523nnn6p/XX3/9HFL169cv/vSnP0WHDh2axY08N/Fg2biJBzTFm3hNOpRKid2RRx4Zt9xySzzwwAPRv3//Wp+nngdt2rSJe++9N88Sk7zxxhsxceLEPCw9Sa/nnntu/kcuF6ZpJr8ULg0cOHCR39uuXbu8LGi55ZbLS30rp5NVaan3vUPLl86d8t2yhjhHi1a+JpSq0l3Nxj4aaH7yudOA14SWcJ1JN/PWXHPNePvtt+P73//+Em/yLU6RN/LcxINl4yYe0BRv4rVu6o/spZn1brvttvwPVR5CnmaFSXf10uvw4cNzMZSan6fiJ4VYKYgq9z8YPHhwDp8OOOCAGDNmTN7Haaedlve9qOAJAKCly/8x9847uT5ampt8i1PkjTw38WDZuIkHNMWbeE06lBo7dmx+3XbbbWutTzPCHHTQQfnniy++OP+xqYhKPQ3SzHpXXHFF9batWrXKj/4dfvjhubDq1KlTDBs2LM4666yC/xoAgMZx/PHHx2677ZYf2Zs0aVKMHj0610j77rvvUt3kAwBoCE06lEqp3dIMCbv88svzsjipALvzzjvr+egAAJqHDz74IAdQn3zySX60buutt44nnngi/7w0N/kAACoulAIAYNndeOONy3yTDwCgvjX/h4kBAAAAaHaEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOGEUgAAAAAUTigFAAAAQOEqKpS6/PLLY7XVVov27dvHZpttFk899VRjHxIAQJOiXgIAilIxodQf//jHOPbYY2P06NHx3HPPxQYbbBBDhgyJKVOmNPahAQA0CeolAKBIFRNKXXTRRXHooYfGwQcfHAMHDowrr7wyOnbsGP/zP//T2IcGANAkqJcAgCK1jgrw1VdfxbPPPhunnHJK9brlllsudtxxx3j88ccX2v7LL7/MS9n06dPz67Rp02L+/Pn1fnyfffZZzJ03L97816cx46s59b5/aOkmfzYzn0PpXErnaXOX/o558+bFp+9+GHNmzm7sw4FmZ+aUafkcaqhrQtpvUiqVopLrpaJrJvUSLBv1EtAU66WKCKX+9a9/5X/slVZaqdb69P71119faPvzzz8/zjzzzIXW9+vXr0GPc/xTzzTo/qGlG//tb0eLcs9jjX0E0Kx9u4GvCTNmzIhu3bpFpdZLjVUzqZdg2aiXgKZUL1VEKFVX6Q5h6qdQlu70TZ06NXr27BlVVVWNemwULyW8q666arz//vvRtWvXxj4coAlwXahs6Y5fKrD69OkTlU7NRE2ujUBNrgmVrbSU9VJFhFIrrLBCtGrVKj766KNa69P73r17L7R9u3bt8lJT9+7dG/w4adrShdTFFKjJdaFytaQRUt+0XkrUTCyKayNQk2tC5eq2FPVSRTQ6b9u2bWy88cZx77331rqTl95vscUWjXpsAABNgXoJAChaRYyUStLQ8mHDhsUmm2wS3/nOd+KSSy6JWbNm5dllAABQLwEAxaqYUGrvvfeOjz/+OEaNGhUffvhhbLjhhjFu3LiFmnnCgtJjCaNHj17o8QSgcrku0FKpl1gWro1ATa4JLI2qUkubzxgAAACAJq8iekoBAAAA0LQIpQAAAAAonFAKAAAAgMIJpaABrLbaannGIqDleOCBB6KqqiqmTZv2tds5/wGWjusltExqJupCKEWzc9BBB+WL3M9//vNa62+99da8vkjXXHNNdO/efaH1Tz/9dIwYMaLQYwFqXyPS0rZt21h99dXjrLPOirlz5y7TfrfccsuYPHlydOvWLb93/gNNmXoJWBI1E02BUIpmqX379nHBBRfEp59+Gk1Rr169omPHjo19GFCxdtppp1wMvfXWW3HcccfFGWecEb/4xS+WaZ+pWOvdu/cS/2PO+Q80FeolYEnUTDQ2oRTN0o477pgvdOeff/5it3nkkUdim222iQ4dOsSqq64aP/3pT2PWrFnVn6eL76677po/79+/f9xwww0LDSG96KKLYtCgQdGpU6e8j//+7/+OmTNnVg9LPfjgg2P69OnVdxjSRTypuZ/99tsv9t5771rHNmfOnFhhhRXiuuuuy++//PLLfHwrrrhiLiC33nrrfOcA+GbatWuXrxH9+vWLww8/PF8z/vrXv+b/MDvwwANj+eWXz0XQzjvvnIuwsvfeey922223/Hk679ddd9248847FxqK7vwHmgP1ErAkaiYam1CKZqlVq1Zx3nnnxWWXXRYffPDBQp+/8847OfUfOnRovPTSS/HHP/4xF10jR46s3iZdZCdNmpQvlH/5y1/iqquuiilTptTaz3LLLReXXnppvPLKK3HttdfGfffdFyeeeGL1sNR0Ee3atWsu2NJy/PHHL3Qs+++/f9x+++3VxVly1113xeeffx577rlnfp/2mY4hfcdzzz2Xh84OGTIkpk6dWq//blCp0n9MffXVV3mY+jPPPJOLrccffzxKpVLssssuuehJjjjiiFzwPPTQQ/H3v/89jzDo3LnzQvtz/gPNgXoJqCs1E4UrQTMzbNiw0u67755/3nzzzUuHHHJI/vmWW24plf8nPXz48NKIESNq/d7DDz9cWm655UpffPFF6bXXXsvbPv3009Wfv/XWW3ndxRdfvNjvvummm0o9e/asfn/11VeXunXrttB2/fr1q97PnDlzSiussELpuuuuq/583333Le29997555kzZ5batGlTuv7666s//+qrr0p9+vQpjRkz5hv8C0Flq3mNmD9/fmn8+PGldu3alfbYY498jj/66KPV2/7rX/8qdejQofSnP/0pvx80aFDpjDPOWOR+77///vz7n376aX7v/AeaMvUSsCRqJpoCI6Vo1lIin5Ly1157rdb6F198MTfUS2l9eUkp+vz582PChAnxxhtvROvWrePb3/529e+kpD0NP63pnnvuiR122CH+4z/+I7p06RIHHHBAfPLJJzmxX1rpe370ox/F9ddfn9+nIfG33XZbvhtQvkuZ7jhstdVW1b/Tpk2b+M53vrPQ3wUsnTvuuCOf92lodxpunoaDpzt+6XzcbLPNqrfr2bNnrLXWWtXnWhoSfs455+TzcfTo0XnkwLJw/gNNgXoJWBw1E41NKEWz9t3vfjcXT6ecckqt9WnY52GHHRYvvPBC9ZIKr/Qc9IABA5Zq3//4xz/iBz/4Qay//vp5mOizzz4bl19+ef4sDWmti3Qxvffee/Nw9zTrTRoWm4bLAw1ju+22y+d9Oue/+OKL/B9jSzPb1E9+8pN49913839QpaHom2yySX7sZVk4/4HGpl4CFkfNRGMTStHspamO0/PH6VnnsnRH79VXX8138xZc0mwQKeVPU50+//zz1b/z9ttv15qdJhVV6U7hhRdeGJtvvnmsueaauadCTWlf8+bNW+IxpmepU+PP1Kshpf8//OEPc7KfpKIv7efRRx+t3j7dBUhN+wYOHLjM/z5QiVLDzXS+9+3bN995S9ZZZ5183j/55JPV26U7+WkkQM1zLZ2r//Vf/xU333xznoXmt7/97SK/w/kPNCfqJWBR1Ew0tn//rw6asTTbS0rVU4PNspNOOikXRqlRZ0rx08U2FV3jx4+PX//617H22mvnmSVGjBgRY8eOzRe7dCFNaXz5zkC6OKcLXUr808wS6QJ45ZVX1vruNGNEusuYEv0NNtggz0yxuGlN04wS6ffffPPNuP/++6vXp2NLM12ccMIJ0aNHj/z/EMaMGZOHvA8fPrzB/t2g0qyxxhqx++67x6GHHhq/+c1v8iMmJ598cn7cJK1Pjj766Dx0Pf1HVfqPrnSupsJsUZz/QHOiXgKWlpqJQjV2UytYloZ8ZRMmTCi1bdu2unFn8tRTT5W+//3vlzp37lzq1KlTaf311y+de+651Z9PmjSptPPOO+dmfqnJ3g033FBaccUVS1deeWX1NhdddFFp5ZVXzk39hgwZkhvv1Wzal/zXf/1XbuaZ1o8ePXqhpn1lr776at4mfZYaCdaUmokeeeSRublfOp6tttoqHz9QP9eIsqlTp5YOOOCA3GyzfF6/+eab1Z+PHDmyNGDAgHwe9urVK2+bGnsuqmln4vwHmir1ErAkaiaagqr0f4qNwaBpSlMlp+Gi5WadAADUpl4CoD4JpahY9913Xx5GmoazT548OU488cT45z//mYeKlp9dBgCoZOolABqSnlJUrNT/4NRTT82zRqTnpFNjvdRQT4EFAPBv6iUAGpKRUgAAAAAUbrnivxIAAACASieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAACieUAgAAAKBwQikAAAAAomj/H9iSEgbdRaN6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analizza distribuzione classi\n",
    "train_labels = [ex['label'] for ex in train_dataset]\n",
    "test_labels = [ex['label'] for ex in test_dataset]\n",
    "\n",
    "train_pos = sum(train_labels)\n",
    "train_neg = len(train_labels) - train_pos\n",
    "\n",
    "test_pos = sum(test_labels)\n",
    "test_neg = len(test_labels) - test_pos\n",
    "\n",
    "print(\"\\nüìä Distribuzione classi:\\n\")\n",
    "print(f\"Train:\")\n",
    "print(f\"   Positivo: {train_pos} ({train_pos/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"   Negativo: {train_neg} ({train_neg/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"\\nTest:\")\n",
    "print(f\"   Positivo: {test_pos} ({test_pos/len(test_labels)*100:.1f}%)\")\n",
    "print(f\"   Negativo: {test_neg} ({test_neg/len(test_labels)*100:.1f}%)\")\n",
    "\n",
    "# Visualizza\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].bar(['Negativo', 'Positivo'], [train_neg, train_pos], color=['#e74c3c', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Train Set')\n",
    "axes[0].set_ylabel('Numero esempi')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "axes[1].bar(['Negativo', 'Positivo'], [test_neg, test_pos], color=['#e74c3c', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Test Set')\n",
    "axes[1].set_ylabel('Numero esempi')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results_day2/class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Grafico salvato in ./results_day2/class_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ SFT su DistilBERT (classification) (60 minuti)\n",
    "\n",
    "**DistilBERT** √® una versione distillata di BERT:\n",
    "- 66M parametri (vs 110M di BERT-base)\n",
    "- 40% pi√π veloce\n",
    "- 97% delle performance di BERT\n",
    "- Ottimo per classification\n",
    "\n",
    "Faremo **full fine-tuning** (tutti i parametri trainable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Caricamento distilbert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello caricato!\n",
      "   Parametri: 67.0M\n"
     ]
    }
   ],
   "source": [
    "# Carica DistilBERT per classification\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "print(f\"‚è≥ Caricamento {MODEL_NAME}...\")\n",
    "\n",
    "tokenizer_distilbert = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model_distilbert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2  # Binary classification\n",
    ")\n",
    "\n",
    "hf_logging.set_verbosity_error()  # o .set_verbosity(hf_logging.ERROR)\n",
    "\n",
    "print(f\"‚úÖ Modello caricato!\")\n",
    "print(f\"   Parametri: {sum(p.numel() for p in model_distilbert.parameters()) / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Tokenizzazione in corso...\n",
      "‚úÖ Tokenizzazione completata!\n"
     ]
    }
   ],
   "source": [
    "# Tokenizza dataset\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenizza testo per DistilBERT.\n",
    "    \n",
    "    Args:\n",
    "        examples: batch di esempi con campo 'text'\n",
    "    \n",
    "    Returns:\n",
    "        Dizionario con input_ids, attention_mask\n",
    "    \"\"\"\n",
    "    return tokenizer_distilbert(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256  # Limita lunghezza per velocit√†\n",
    "    )\n",
    "\n",
    "print(\"‚è≥ Tokenizzazione in corso...\")\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"‚úÖ Tokenizzazione completata!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metriche definite\n"
     ]
    }
   ],
   "source": [
    "# Definisci metriche\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Calcola accuracy e F1 score.\n",
    "    \n",
    "    Args:\n",
    "        eval_pred: tupla (predictions, labels)\n",
    "    \n",
    "    Returns:\n",
    "        Dizionario con metriche\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Metriche definite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training arguments configurati\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./models_day2/distilbert_sft',\n",
    "    eval_strategy='epoch',  # Valuta ogni epoca\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,  # Learning rate tipico per BERT\n",
    "    per_device_train_batch_size=8,  # Batch size per CPU\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,  # 2 epoche per velocit√†\n",
    "    weight_decay=0.01,  # Regolarizzazione L2\n",
    "    logging_dir='./results_day2/logs',\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,  # Carica miglior modello\n",
    "    metric_for_best_model='accuracy',\n",
    "    seed=SEED,\n",
    "    report_to='none'  # Disabilita wandb/tensorboard\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configurati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer inizializzato\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model_distilbert,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer inizializzato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training in corso... (questo richieder√† ~15-20 minuti su CPU)\n",
      "\n",
      "{'loss': 0.6691, 'grad_norm': 2.472095012664795, 'learning_rate': 1.8040000000000003e-05, 'epoch': 0.2}\n",
      "{'loss': 0.5218, 'grad_norm': 11.319575309753418, 'learning_rate': 1.6040000000000002e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3998, 'grad_norm': 5.659884452819824, 'learning_rate': 1.4040000000000001e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3972, 'grad_norm': 3.707961320877075, 'learning_rate': 1.204e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3009, 'grad_norm': 7.6958794593811035, 'learning_rate': 1.004e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 0.2902233600616455, 'eval_accuracy': 0.88, 'eval_f1': 0.8799923195084485, 'eval_runtime': 104.183, 'eval_samples_per_second': 4.799, 'eval_steps_per_second': 0.605, 'epoch': 1.0}\n",
      "{'loss': 0.2155, 'grad_norm': 9.489081382751465, 'learning_rate': 8.040000000000001e-06, 'epoch': 1.2}\n",
      "{'loss': 0.3068, 'grad_norm': 3.5985476970672607, 'learning_rate': 6.040000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 0.1692, 'grad_norm': 3.244854211807251, 'learning_rate': 4.04e-06, 'epoch': 1.6}\n",
      "{'loss': 0.1895, 'grad_norm': 1.457921028137207, 'learning_rate': 2.04e-06, 'epoch': 1.8}\n",
      "{'loss': 0.2276, 'grad_norm': 7.547558784484863, 'learning_rate': 4e-08, 'epoch': 2.0}\n",
      "{'eval_loss': 0.36099502444267273, 'eval_accuracy': 0.874, 'eval_f1': 0.873995463836698, 'eval_runtime': 98.2597, 'eval_samples_per_second': 5.089, 'eval_steps_per_second': 0.641, 'epoch': 2.0}\n",
      "{'train_runtime': 3562.3173, 'train_samples_per_second': 1.123, 'train_steps_per_second': 0.14, 'train_loss': 0.3397474308013916, 'epoch': 2.0}\n",
      "\n",
      "‚úÖ Training completato in 59.4 minuti!\n"
     ]
    }
   ],
   "source": [
    "# Training (questo richieder√† ~15-20 minuti su CPU)\n",
    "print(\"\\n‚è≥ Training in corso... (questo richieder√† ~15-20 minuti su CPU)\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "train_result = trainer.train()\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Training completato in {training_time/60:.1f} minuti!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Valutazione finale...\n",
      "{'eval_loss': 0.2902233600616455, 'eval_accuracy': 0.88, 'eval_f1': 0.8799923195084485, 'eval_runtime': 102.4911, 'eval_samples_per_second': 4.878, 'eval_steps_per_second': 0.615, 'epoch': 2.0}\n",
      "\n",
      "üìä Risultati:\n",
      "   Accuracy: 0.8800\n",
      "   F1 Score: 0.8800\n",
      "   Loss: 0.2902\n"
     ]
    }
   ],
   "source": [
    "# Valutazione finale\n",
    "print(\"\\n‚è≥ Valutazione finale...\")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\nüìä Risultati:\")\n",
    "print(f\"   Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"   F1 Score: {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"   Loss: {eval_results['eval_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Confusion matrix salvata in ./results_day2/confusion_matrix_distilbert.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Visualizza\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['Negativo', 'Positivo'])\n",
    "ax.set_yticklabels(['Negativo', 'Positivo'])\n",
    "\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix - DistilBERT SFT')\n",
    "\n",
    "# Aggiungi valori\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = ax.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.max()/2 else 'black', fontsize=20)\n",
    "\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results_day2/confusion_matrix_distilbert.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Confusion matrix salvata in ./results_day2/confusion_matrix_distilbert.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello salvato in ./models_day2/distilbert_sft_final\n"
     ]
    }
   ],
   "source": [
    "# Salva modello\n",
    "trainer.save_model('./models_day2/distilbert_sft_final')\n",
    "print(\"‚úÖ Modello salvato in ./models_day2/distilbert_sft_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Osservazioni:\n",
    "\n",
    "1. **Accuracy attesa**: 85-92% (dipende da seed e dataset)\n",
    "2. **Full fine-tuning**: tutti i 66M parametri sono stati aggiornati\n",
    "3. **Tempo**: ~15-20 minuti su CPU per 2 epoche\n",
    "4. **Overfitting**: con pi√π epoche (>3) rischio overfitting su 2000 esempi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ LoRA su GPT-2 (50 minuti)\n",
    "\n",
    "Ora applichiamo **LoRA** su GPT-2 per un task generativo (continuazione testo).\n",
    "\n",
    "### Vantaggi di LoRA:\n",
    "- **Parametri trainable ridotti**: da 117M a ~0.3M (99.7% riduzione)\n",
    "- **Memoria ridotta**: solo adapter salvati (~1MB vs ~450MB)\n",
    "- **Training pi√π veloce**: meno parametri da aggiornare\n",
    "- **Modulare**: puoi avere adapter diversi per task diversi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Caricamento GPT-2...\n",
      "‚úÖ GPT-2 caricato!\n",
      "   Parametri totali: 124.4M\n"
     ]
    }
   ],
   "source": [
    "# Carica GPT-2\n",
    "print(\"‚è≥ Caricamento GPT-2...\")\n",
    "\n",
    "tokenizer_gpt2 = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token\n",
    "\n",
    "model_gpt2_base = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "\n",
    "total_params = sum(p.numel() for p in model_gpt2_base.parameters())\n",
    "print(f\"‚úÖ GPT-2 caricato!\")\n",
    "print(f\"   Parametri totali: {total_params / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LoRA config:\n",
      "   Rank (r): 8\n",
      "   Alpha: 32\n",
      "   Target modules: {'c_attn'}\n"
     ]
    }
   ],
   "source": [
    "# Configura LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  # Task: causal language modeling\n",
    "    r=8,  # Rank: dimensione bottleneck (4-64 tipicamente)\n",
    "    lora_alpha=32,  # Scaling factor (tipicamente 2*r)\n",
    "    lora_dropout=0.1,  # Dropout per regolarizzazione\n",
    "    target_modules=['c_attn'],  # Moduli da adattare (attention in GPT-2)\n",
    "    bias='none'  # Non adattare bias\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LoRA config:\")\n",
    "print(f\"   Rank (r): {lora_config.r}\")\n",
    "print(f\"   Alpha: {lora_config.lora_alpha}\")\n",
    "print(f\"   Target modules: {lora_config.target_modules}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n",
      "\n",
      "üí° Riduzione parametri: 124.4M ‚Üí 0.29M (0.24%)\n"
     ]
    }
   ],
   "source": [
    "# Applica LoRA al modello\n",
    "model_gpt2_lora = get_peft_model(model_gpt2_base, lora_config)\n",
    "\n",
    "# Stampa info parametri\n",
    "model_gpt2_lora.print_trainable_parameters()\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model_gpt2_lora.parameters() if p.requires_grad)\n",
    "print(f\"\\nüí° Riduzione parametri: {total_params / 1e6:.1f}M ‚Üí {trainable_params / 1e6:.2f}M ({trainable_params/total_params*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Tokenizzazione per CLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed688d8fe9b4ac7b2d864d621e2a292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd15297677c4fb29cc3084e4201cfe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenizzazione completata!\n"
     ]
    }
   ],
   "source": [
    "# Prepara dataset per causal LM\n",
    "# Usiamo le recensioni IMDB come testo da continuare\n",
    "\n",
    "def tokenize_for_clm(examples):\n",
    "    \"\"\"\n",
    "    Tokenizza per causal language modeling.\n",
    "    \n",
    "    Args:\n",
    "        examples: batch con campo 'text'\n",
    "    \n",
    "    Returns:\n",
    "        Dizionario con input_ids, attention_mask, labels\n",
    "    \"\"\"\n",
    "    # Tokenizza\n",
    "    tokenized = tokenizer_gpt2(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128,  # Pi√π corto per velocit√†\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # Per CLM, labels = input_ids\n",
    "    tokenized['labels'] = tokenized['input_ids'].copy()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "print(\"‚è≥ Tokenizzazione per CLM...\")\n",
    "\n",
    "# Usa subset pi√π piccolo per velocit√†\n",
    "train_dataset_small = train_dataset.select(range(500))\n",
    "test_dataset_small = test_dataset.select(range(100))\n",
    "\n",
    "tokenized_train_clm = train_dataset_small.map(tokenize_for_clm, batched=True, remove_columns=['text', 'label'])\n",
    "tokenized_test_clm = test_dataset_small.map(tokenize_for_clm, batched=True, remove_columns=['text', 'label'])\n",
    "\n",
    "print(\"‚úÖ Tokenizzazione completata!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training arguments configurati\n"
     ]
    }
   ],
   "source": [
    "# Training arguments per LoRA\n",
    "training_args_lora = TrainingArguments(\n",
    "    output_dir='./models_day2/gpt2_lora',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=1e-4,  # LR pi√π alto per LoRA\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='loss',\n",
    "    seed=SEED,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configurati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer LoRA inizializzato\n"
     ]
    }
   ],
   "source": [
    "# Trainer per LoRA\n",
    "trainer_lora = Trainer(\n",
    "    model=model_gpt2_lora,\n",
    "    args=training_args_lora,\n",
    "    train_dataset=tokenized_train_clm,\n",
    "    eval_dataset=tokenized_test_clm\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer LoRA inizializzato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training LoRA in corso... (~10-15 minuti su CPU)\n",
      "\n",
      "{'loss': 4.1341, 'grad_norm': 0.6845741271972656, 'learning_rate': 9.360000000000001e-05, 'epoch': 0.2}\n",
      "{'loss': 4.1485, 'grad_norm': 0.6877920031547546, 'learning_rate': 8.693333333333334e-05, 'epoch': 0.4}\n",
      "{'loss': 3.9723, 'grad_norm': 0.7321832180023193, 'learning_rate': 8.026666666666666e-05, 'epoch': 0.6}\n",
      "{'loss': 3.8363, 'grad_norm': 0.7339245080947876, 'learning_rate': 7.36e-05, 'epoch': 0.8}\n",
      "{'loss': 3.8547, 'grad_norm': 0.9442994594573975, 'learning_rate': 6.693333333333334e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 3.5544018745422363, 'eval_runtime': 38.5821, 'eval_samples_per_second': 2.592, 'eval_steps_per_second': 0.648, 'epoch': 1.0}\n",
      "{'loss': 3.6769, 'grad_norm': 0.7513611316680908, 'learning_rate': 6.026666666666667e-05, 'epoch': 1.2}\n",
      "{'loss': 3.7893, 'grad_norm': 0.9228888154029846, 'learning_rate': 5.360000000000001e-05, 'epoch': 1.4}\n",
      "{'loss': 3.7176, 'grad_norm': 0.9733878970146179, 'learning_rate': 4.6933333333333333e-05, 'epoch': 1.6}\n",
      "{'loss': 3.7518, 'grad_norm': 0.795409619808197, 'learning_rate': 4.026666666666667e-05, 'epoch': 1.8}\n",
      "{'loss': 3.6287, 'grad_norm': 0.8822696208953857, 'learning_rate': 3.3600000000000004e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 3.5251777172088623, 'eval_runtime': 32.7908, 'eval_samples_per_second': 3.05, 'eval_steps_per_second': 0.762, 'epoch': 2.0}\n",
      "{'loss': 3.7417, 'grad_norm': 0.8114709854125977, 'learning_rate': 2.6933333333333332e-05, 'epoch': 2.2}\n",
      "{'loss': 3.5509, 'grad_norm': 0.7564374208450317, 'learning_rate': 2.0266666666666667e-05, 'epoch': 2.4}\n",
      "{'loss': 3.6299, 'grad_norm': 0.9280773997306824, 'learning_rate': 1.3600000000000002e-05, 'epoch': 2.6}\n",
      "{'loss': 3.806, 'grad_norm': 0.7194424867630005, 'learning_rate': 6.933333333333334e-06, 'epoch': 2.8}\n",
      "{'loss': 3.6768, 'grad_norm': 1.0062029361724854, 'learning_rate': 2.6666666666666667e-07, 'epoch': 3.0}\n",
      "{'eval_loss': 3.519883394241333, 'eval_runtime': 32.6622, 'eval_samples_per_second': 3.062, 'eval_steps_per_second': 0.765, 'epoch': 3.0}\n",
      "{'train_runtime': 1356.1241, 'train_samples_per_second': 1.106, 'train_steps_per_second': 0.277, 'train_loss': 3.7943558146158853, 'epoch': 3.0}\n",
      "\n",
      "‚úÖ Training LoRA completato in 22.6 minuti!\n"
     ]
    }
   ],
   "source": [
    "# Training LoRA (pi√π veloce di full fine-tuning)\n",
    "print(\"\\n‚è≥ Training LoRA in corso... (~10-15 minuti su CPU)\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "train_result_lora = trainer_lora.train()\n",
    "end_time = time.time()\n",
    "\n",
    "training_time_lora = end_time - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Training LoRA completato in {training_time_lora/60:.1f} minuti!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Adapter LoRA salvato in ./models_day2/gpt2_lora_adapter\n",
      "   Dimensione adapter: 1.13 MB\n",
      "   üí° Confronto: modello completo GPT-2 ~500MB, adapter LoRA ~1.13MB\n"
     ]
    }
   ],
   "source": [
    "# Salva adapter LoRA\n",
    "model_gpt2_lora.save_pretrained('./models_day2/gpt2_lora_adapter')\n",
    "print(\"‚úÖ Adapter LoRA salvato in ./models_day2/gpt2_lora_adapter\")\n",
    "\n",
    "# Verifica dimensione\n",
    "import os\n",
    "adapter_size = sum(os.path.getsize(f'./models_day2/gpt2_lora_adapter/{f}') for f in os.listdir('./models_day2/gpt2_lora_adapter') if os.path.isfile(f'./models_day2/gpt2_lora_adapter/{f}'))\n",
    "print(f\"   Dimensione adapter: {adapter_size / (1024**2):.2f} MB\")\n",
    "print(f\"   üí° Confronto: modello completo GPT-2 ~500MB, adapter LoRA ~{adapter_size / (1024**2):.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Test generazione con LoRA:\n",
      "\n",
      "Prompt: This movie is absolutely\n",
      "\n",
      "Output: This movie is absolutely amazing. I had been hoping to see a lot of it and this movie really does stand out. It's a comedy with an incredibly good story. The characters are all very likable and all very well-acted. It is an entertaining movie,\n"
     ]
    }
   ],
   "source": [
    "# Test generazione con LoRA\n",
    "test_prompt = \"This movie is absolutely\"\n",
    "\n",
    "print(f\"\\nüìù Test generazione con LoRA:\\n\")\n",
    "print(f\"Prompt: {test_prompt}\\n\")\n",
    "\n",
    "inputs = tokenizer_gpt2(test_prompt, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_gpt2_lora.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer_gpt2.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer_gpt2.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Output: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Osservazioni LoRA:\n",
    "\n",
    "1. **Parametri trainable**: ridotti del 99.7% (da 117M a ~0.3M)\n",
    "2. **Velocit√†**: training ~2-3x pi√π veloce di full fine-tuning\n",
    "3. **Memoria**: adapter ~1-2MB vs ~500MB modello completo\n",
    "4. **Qualit√†**: performance simili a full fine-tuning per molti task\n",
    "5. **Modularit√†**: puoi caricare adapter diversi sullo stesso modello base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ QLoRA su GPT-2 (50 minuti)\n",
    "\n",
    "**QLoRA** combina **quantizzazione** (int4/int8) + **LoRA** per ridurre ulteriormente la memoria.\n",
    "\n",
    "### Vantaggi:\n",
    "- **Memoria ridotta**: ~75% rispetto a LoRA standard\n",
    "- **Permette fine-tuning di modelli grandi**: es. LLaMA-65B su GPU 24GB\n",
    "- **Velocit√†**: leggermente pi√π lenta per quantizzazione, ma gestibile\n",
    "\n",
    "### Libreria: bitsandbytes\n",
    "- Quantizzazione int4/int8 ottimizzata\n",
    "- Integrata con Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Caricamento GPT-2 con quantizzazione int8...\n",
      "‚úÖ Modello quantizzato caricato!\n"
     ]
    }
   ],
   "source": [
    "# Carica GPT-2 con quantizzazione int8\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Config quantizzazione\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # Quantizzazione int8 (int4 richiede GPU)\n",
    "    bnb_8bit_compute_dtype=torch.float32  # Compute in FP32\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Caricamento GPT-2 con quantizzazione int8...\")\n",
    "\n",
    "try:\n",
    "    model_gpt2_quantized = AutoModelForCausalLM.from_pretrained(\n",
    "        'gpt2',\n",
    "        quantization_config=bnb_config,\n",
    "        device_map='auto'  # Automatic device placement\n",
    "    )\n",
    "    print(\"‚úÖ Modello quantizzato caricato!\")\n",
    "    quantization_available = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Quantizzazione non disponibile su CPU: {e}\")\n",
    "    print(\"   Carico modello standard per dimostrazione...\")\n",
    "    model_gpt2_quantized = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "    quantization_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello preparato per k-bit training\n"
     ]
    }
   ],
   "source": [
    "# Prepara modello per k-bit training (se quantizzato)\n",
    "if quantization_available:\n",
    "    model_gpt2_quantized = prepare_model_for_kbit_training(model_gpt2_quantized)\n",
    "    print(\"‚úÖ Modello preparato per k-bit training\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Usando modello standard (quantizzazione non disponibile)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ QLoRA applicato!\n",
      "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364\n"
     ]
    }
   ],
   "source": [
    "# Applica LoRA al modello quantizzato (QLoRA)\n",
    "qlora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['c_attn'],\n",
    "    bias='none'\n",
    ")\n",
    "\n",
    "model_gpt2_qlora = get_peft_model(model_gpt2_quantized, qlora_config)\n",
    "\n",
    "print(\"‚úÖ QLoRA applicato!\")\n",
    "model_gpt2_qlora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer QLoRA inizializzato\n"
     ]
    }
   ],
   "source": [
    "# Training QLoRA (stesso setup di LoRA)\n",
    "training_args_qlora = TrainingArguments(\n",
    "    output_dir='./models_day2/gpt2_qlora',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='loss',\n",
    "    seed=SEED,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer_qlora = Trainer(\n",
    "    model=model_gpt2_qlora,\n",
    "    args=training_args_qlora,\n",
    "    train_dataset=tokenized_train_clm,\n",
    "    eval_dataset=tokenized_test_clm\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer QLoRA inizializzato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training QLoRA in corso... (~10-15 minuti)\n",
      "\n",
      "{'loss': 4.138, 'grad_norm': 0.6819418668746948, 'learning_rate': 9.360000000000001e-05, 'epoch': 0.2}\n",
      "{'loss': 4.1506, 'grad_norm': 0.7382024526596069, 'learning_rate': 8.693333333333334e-05, 'epoch': 0.4}\n",
      "{'loss': 3.9743, 'grad_norm': 0.7665440440177917, 'learning_rate': 8.026666666666666e-05, 'epoch': 0.6}\n",
      "{'loss': 3.8427, 'grad_norm': 0.779867947101593, 'learning_rate': 7.36e-05, 'epoch': 0.8}\n",
      "{'loss': 3.8591, 'grad_norm': 0.9533146023750305, 'learning_rate': 6.693333333333334e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 3.5569794178009033, 'eval_runtime': 2220.4891, 'eval_samples_per_second': 0.045, 'eval_steps_per_second': 0.011, 'epoch': 1.0}\n",
      "{'loss': 3.6779, 'grad_norm': 0.7998232245445251, 'learning_rate': 6.026666666666667e-05, 'epoch': 1.2}\n",
      "{'loss': 3.7879, 'grad_norm': 1.0565282106399536, 'learning_rate': 5.360000000000001e-05, 'epoch': 1.4}\n",
      "{'loss': 3.7154, 'grad_norm': 0.963711678981781, 'learning_rate': 4.6933333333333333e-05, 'epoch': 1.6}\n",
      "{'loss': 3.7503, 'grad_norm': 0.8339182734489441, 'learning_rate': 4.026666666666667e-05, 'epoch': 1.8}\n",
      "{'loss': 3.6285, 'grad_norm': 0.8740963935852051, 'learning_rate': 3.3600000000000004e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 3.526191473007202, 'eval_runtime': 2226.5292, 'eval_samples_per_second': 0.045, 'eval_steps_per_second': 0.011, 'epoch': 2.0}\n",
      "{'loss': 3.7401, 'grad_norm': 0.8629146814346313, 'learning_rate': 2.6933333333333332e-05, 'epoch': 2.2}\n",
      "{'loss': 3.5491, 'grad_norm': 0.8314816951751709, 'learning_rate': 2.0266666666666667e-05, 'epoch': 2.4}\n",
      "{'loss': 3.6284, 'grad_norm': 0.9878798127174377, 'learning_rate': 1.3600000000000002e-05, 'epoch': 2.6}\n",
      "{'loss': 3.8035, 'grad_norm': 0.7691548466682434, 'learning_rate': 6.933333333333334e-06, 'epoch': 2.8}\n",
      "{'loss': 3.6742, 'grad_norm': 1.0120131969451904, 'learning_rate': 2.6666666666666667e-07, 'epoch': 3.0}\n",
      "{'eval_loss': 3.520111083984375, 'eval_runtime': 2223.063, 'eval_samples_per_second': 0.045, 'eval_steps_per_second': 0.011, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8647.464, 'train_samples_per_second': 0.173, 'train_steps_per_second': 0.043, 'train_loss': 3.7946671549479167, 'epoch': 3.0}\n",
      "\n",
      "‚úÖ Training QLoRA completato in 144.1 minuti!\n"
     ]
    }
   ],
   "source": [
    "# Training QLoRA\n",
    "print(\"\\n‚è≥ Training QLoRA in corso... (~10-15 minuti)\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "train_result_qlora = trainer_qlora.train()\n",
    "end_time = time.time()\n",
    "\n",
    "training_time_qlora = end_time - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Training QLoRA completato in {training_time_qlora/60:.1f} minuti!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Adapter QLoRA salvato in ./models_day2/gpt2_qlora_adapter\n"
     ]
    }
   ],
   "source": [
    "# Salva adapter QLoRA\n",
    "model_gpt2_qlora.save_pretrained('./models_day2/gpt2_qlora_adapter')\n",
    "print(\"‚úÖ Adapter QLoRA salvato in ./models_day2/gpt2_qlora_adapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Test generazione con QLoRA:\n",
      "\n",
      "Prompt: This movie is absolutely\n",
      "\n",
      "Output: This movie is absolutely amazing. I had been hoping to see a lot of it and this movie really does stand out. It's a comedy with an incredibly good story. The characters are all very likable and all very well-acted. It is an entertaining movie,\n"
     ]
    }
   ],
   "source": [
    "# Test generazione con QLoRA\n",
    "test_prompt = \"This movie is absolutely\"\n",
    "\n",
    "print(f\"\\nüìù Test generazione con QLoRA:\\n\")\n",
    "print(f\"Prompt: {test_prompt}\\n\")\n",
    "\n",
    "inputs = tokenizer_gpt2(test_prompt, return_tensors='pt')\n",
    "if quantization_available:\n",
    "    inputs = {k: v.to(model_gpt2_qlora.device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_gpt2_qlora.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer_gpt2.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer_gpt2.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Output: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Osservazioni QLoRA:\n",
    "\n",
    "1. **Memoria**: ridotta del ~75% rispetto a LoRA standard\n",
    "2. **Quantizzazione**: int8 su CPU, int4 richiede GPU\n",
    "3. **Performance**: leggermente inferiore a LoRA, ma accettabile\n",
    "4. **Use case**: essenziale per fine-tuning di modelli >10B parametri su hardware consumer\n",
    "\n",
    "### Quando usare QLoRA:\n",
    "- Modelli grandi (>7B parametri)\n",
    "- Hardware limitato (GPU <24GB, o CPU)\n",
    "- Deployment su edge devices\n",
    "- Quando serve ridurre costi cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Confronto base vs fine-tuned (30 minuti)\n",
    "\n",
    "Confrontiamo i modelli:\n",
    "1. GPT-2 base (no fine-tuning)\n",
    "2. GPT-2 + LoRA\n",
    "3. GPT-2 + QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Confronto generazione:\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Prompt: This movie is absolutely\n",
      "================================================================================\n",
      "\n",
      "Base: This movie is absolutely fantastic. I loved every second of it. I don't know if the movie was filmed on a high budget, but the movie is so great. The only downside is that there are some scenes where the camera is moving too fast and the camera is\n",
      "\n",
      "LoRA: This movie is absolutely fantastic. I was so excited to see it when I saw it, but the scenes were so much better. I have to say that the pacing was a bit off, and I was looking forward to seeing more action and gore. I also felt like\n",
      "\n",
      "QLoRA: This movie is absolutely amazing, and it is just incredible. It's a great movie that has a very strong ending and a very satisfying ending. I am not a huge fan of the ending and would never watch this movie again.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Prompt: The acting was\n",
      "================================================================================\n",
      "\n",
      "Base: The acting was well-received, with several productions in the U.S. and Europe. The film was released in September of 2001.\n",
      "\n",
      "LoRA: The acting was excellent. The acting was great. The humor was good and the comedy was funny. The acting was great. The acting was great. The humor was good and the comedy was funny. The acting was great. The acting was great. The humor was\n",
      "\n",
      "QLoRA: The acting was shot with a \"slim\" camera, but the performance was so good that the only other actors in the film were John Hurt and Robert Downey Jr. The movie's opening scene is a hilarious comedy that takes place in the fictional world of a\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Prompt: I would recommend this film because\n",
      "================================================================================\n",
      "\n",
      "Base: I would recommend this film because of the characters and the music.\n",
      "\n",
      "LoRA: I would recommend this film because it is a really good example of how a great film can be made to make your mind up.\n",
      "\n",
      "QLoRA: I would recommend this film because it is a masterpiece. I was a little disappointed when I saw the trailer for it, but it was still a great film. The characters are pretty good and the pacing is great.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Funzione per generare con modello\n",
    "def generate_comparison(model, tokenizer, prompt, max_new_tokens=50):\n",
    "    \"\"\"\n",
    "    Genera testo per confronto.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Prompt di test\n",
    "test_prompts = [\n",
    "    \"This movie is absolutely\",\n",
    "    \"The acting was\",\n",
    "    \"I would recommend this film because\"\n",
    "]\n",
    "\n",
    "print(\"üìù Confronto generazione:\\n\")\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Base\n",
    "    base_output = generate_comparison(model_gpt2_base, tokenizer_gpt2, prompt)\n",
    "    print(f\"Base: {base_output}\\n\")\n",
    "    \n",
    "    # LoRA\n",
    "    lora_output = generate_comparison(model_gpt2_lora, tokenizer_gpt2, prompt)\n",
    "    print(f\"LoRA: {lora_output}\\n\")\n",
    "    \n",
    "    # QLoRA\n",
    "    qlora_output = generate_comparison(model_gpt2_qlora, tokenizer_gpt2, prompt)\n",
    "    print(f\"QLoRA: {qlora_output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Confronto Metodi di Fine-Tuning:\n",
      "\n",
      "                       Metodo Parametri Totali Parametri Trainable    Memoria Modello Dimensione Salvata Tempo Training\n",
      "Full Fine-Tuning (DistilBERT)              66M          66M (100%)             ~250MB             ~250MB       59.4 min\n",
      "                 LoRA (GPT-2)             117M        ~0.3M (0.3%)             ~500MB   ~1-2MB (adapter)       22.6 min\n",
      "                QLoRA (GPT-2)             117M        ~0.3M (0.3%) ~125MB (quantized)   ~1-2MB (adapter)      144.1 min\n",
      "\n",
      "‚úÖ Tabella salvata in ./results_day2/finetuning_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Confronto metriche training\n",
    "comparison_data = {\n",
    "    'Metodo': ['Full Fine-Tuning (DistilBERT)', 'LoRA (GPT-2)', 'QLoRA (GPT-2)'],\n",
    "    'Parametri Totali': ['66M', '117M', '117M'],\n",
    "    'Parametri Trainable': ['66M (100%)', '~0.3M (0.3%)', '~0.3M (0.3%)'],\n",
    "    'Memoria Modello': ['~250MB', '~500MB', '~125MB (quantized)'],\n",
    "    'Dimensione Salvata': ['~250MB', '~1-2MB (adapter)', '~1-2MB (adapter)'],\n",
    "    'Tempo Training': [f'{training_time/60:.1f} min', f'{training_time_lora/60:.1f} min', f'{training_time_qlora/60:.1f} min']\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\nüìä Confronto Metodi di Fine-Tuning:\\n\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "df_comparison.to_csv('./results_day2/finetuning_comparison.csv', index=False)\n",
    "print(\"\\n‚úÖ Tabella salvata in ./results_day2/finetuning_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Conclusioni:\n",
    "\n",
    "**Full Fine-Tuning**:\n",
    "- ‚úÖ Performance massime\n",
    "- ‚ùå Lento, costoso, richiede molta memoria\n",
    "- üéØ Quando usare: dataset grandi (>10K esempi), task critici\n",
    "\n",
    "**LoRA**:\n",
    "- ‚úÖ 99% riduzione parametri, veloce, modulare\n",
    "- ‚úÖ Performance simili a full fine-tuning\n",
    "- üéØ Quando usare: maggior parte dei casi, default choice\n",
    "\n",
    "**QLoRA**:\n",
    "- ‚úÖ 75% riduzione memoria, permette modelli grandi su hardware limitato\n",
    "- ‚ö†Ô∏è Leggermente pi√π lento, performance leggermente inferiori\n",
    "- üéØ Quando usare: modelli >7B parametri, hardware limitato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Esercizi TODO\n",
    "\n",
    "### Esercizio 1: Hyperparameter sweep LoRA\n",
    "Testa rank diversi (r=4, 8, 16, 32) e confronta performance e velocit√†.\n",
    "\n",
    "### Esercizio 2: Target modules\n",
    "Prova a modificare `target_modules` in LoRA (es. ['c_attn', 'c_proj']) e osserva differenze.\n",
    "\n",
    "### Esercizio 3: Full fine-tuning GPT-2\n",
    "Fai full fine-tuning di GPT-2 (senza LoRA) e confronta con LoRA.\n",
    "\n",
    "### Esercizio 4: Multi-adapter\n",
    "Crea due adapter LoRA diversi (uno per sentiment positivo, uno per negativo) e confronta output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Esercizio 1 - Hyperparameter sweep LoRA\n",
    "# Scrivi qui il tuo codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Esercizio 2 - Target modules\n",
    "# Scrivi qui il tuo codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Esercizio 3 - Full fine-tuning GPT-2\n",
    "# Scrivi qui il tuo codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Esercizio 4 - Multi-adapter\n",
    "# Scrivi qui il tuo codice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Soluzioni degli esercizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUZIONE Esercizio 2: Target modules\n",
    "\n",
    "# Prova con pi√π target modules\n",
    "lora_config_extended = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['c_attn', 'c_proj'],  # Aggiungi c_proj\n",
    "    bias='none'\n",
    ")\n",
    "\n",
    "model_test = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "model_test_lora = get_peft_model(model_test, lora_config_extended)\n",
    "\n",
    "print(\"\\nüìä Confronto target modules:\\n\")\n",
    "print(\"Solo c_attn:\")\n",
    "model_gpt2_lora.print_trainable_parameters()\n",
    "\n",
    "print(\"\\nc_attn + c_proj:\")\n",
    "model_test_lora.print_trainable_parameters()\n",
    "\n",
    "print(\"\\nüí° Pi√π target modules = pi√π parametri trainable = potenzialmente migliori performance ma pi√π lento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Conclusione Day 2\n",
    "\n",
    "Oggi abbiamo:\n",
    "1. ‚úÖ Compreso **SFT** e differenze da pre-training\n",
    "2. ‚úÖ Preparato dataset **IMDB** per sentiment analysis\n",
    "3. ‚úÖ Fatto **full fine-tuning** di DistilBERT (66M parametri)\n",
    "4. ‚úÖ Implementato **LoRA** su GPT-2 (riduzione 99.7% parametri)\n",
    "5. ‚úÖ Implementato **QLoRA** con quantizzazione int8\n",
    "6. ‚úÖ Confrontato **base vs fine-tuned** su prompt identici\n",
    "\n",
    "**Prossimi passi (Day 3)**:\n",
    "- RLHF (Reinforcement Learning from Human Feedback)\n",
    "- PPO (Proximal Policy Optimization)\n",
    "- DPO (Direct Preference Optimization)\n",
    "- Libreria trl di Hugging Face\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ File generati\n",
    "\n",
    "```\n",
    "./results_day2/\n",
    "‚îú‚îÄ‚îÄ class_distribution.png\n",
    "‚îú‚îÄ‚îÄ confusion_matrix_distilbert.png\n",
    "‚îú‚îÄ‚îÄ finetuning_comparison.csv\n",
    "‚îî‚îÄ‚îÄ logs/\n",
    "\n",
    "./models_day2/\n",
    "‚îú‚îÄ‚îÄ distilbert_sft_final/\n",
    "‚îú‚îÄ‚îÄ gpt2_lora_adapter/\n",
    "‚îî‚îÄ‚îÄ gpt2_qlora_adapter/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
