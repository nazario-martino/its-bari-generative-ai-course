{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b914b8-f9c3-466c-a8e8-cbed8170ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANGELAANGUILANO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "# Assicurati di avere i token di NLTK per il tokenization\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3904a6a5-9d78-4097-84cb-ea76650271d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Caricamento del testo (usa un libro dell'autore che desideri)\n",
    "with open('testo_autore.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "# Tokenizzazione del testo\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Creazione del vocabolario unico (mappa le parole in indici)\n",
    "vocab = sorted(set(tokens))\n",
    "vocab_size = len(vocab)\n",
    "word_to_int = {word: i for i, word in enumerate(vocab)}\n",
    "int_to_word = {i: word for i, word in enumerate(vocab)}\n",
    "\n",
    "# Creazione delle sequenze di input (X) e target (y)\n",
    "seq_length = 40  # Numero di parole in ciascuna sequenza\n",
    "sequences = []\n",
    "\n",
    "for i in range(seq_length, len(tokens)):\n",
    "    seq = tokens[i-seq_length:i]  # Sequenza di 40 parole\n",
    "    label = tokens[i]  # Parola successiva\n",
    "    sequences.append([word_to_int[word] for word in seq] + [word_to_int[label]])\n",
    "\n",
    "# Creazione degli input (X) e degli output (y)\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ef90ee-7420-4f90-a4e6-3a327f77ff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANGELAANGUILANO\\simple-environment\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 541ms/step - accuracy: 0.0365 - loss: 5.9359\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 542ms/step - accuracy: 0.0447 - loss: 5.3284\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 539ms/step - accuracy: 0.0529 - loss: 5.2133\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 512ms/step - accuracy: 0.0455 - loss: 5.1867\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 482ms/step - accuracy: 0.0484 - loss: 5.1744\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 492ms/step - accuracy: 0.0484 - loss: 5.1718\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.0425 - loss: 5.1698\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 481ms/step - accuracy: 0.0492 - loss: 5.1676\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 505ms/step - accuracy: 0.0581 - loss: 5.1614\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 442ms/step - accuracy: 0.0499 - loss: 5.1582\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 471ms/step - accuracy: 0.0626 - loss: 5.1508\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.0879 - loss: 5.1289\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.0849 - loss: 5.0838\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.0909 - loss: 5.0036\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 432ms/step - accuracy: 0.0954 - loss: 4.9045\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 474ms/step - accuracy: 0.0976 - loss: 4.7817\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.1215 - loss: 4.6552\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 486ms/step - accuracy: 0.1379 - loss: 4.5442\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 484ms/step - accuracy: 0.1475 - loss: 4.4364\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 451ms/step - accuracy: 0.1557 - loss: 4.3334\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 501ms/step - accuracy: 0.1639 - loss: 4.2304\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 503ms/step - accuracy: 0.1841 - loss: 4.1292\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.1759 - loss: 4.0505\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.1937 - loss: 3.9359\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.1997 - loss: 3.8531\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 432ms/step - accuracy: 0.2116 - loss: 3.7602\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 464ms/step - accuracy: 0.2295 - loss: 3.6620\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 481ms/step - accuracy: 0.2370 - loss: 3.5586\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.2556 - loss: 3.4648\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.2519 - loss: 3.3735\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 509ms/step - accuracy: 0.2765 - loss: 3.2767\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.2951 - loss: 3.1999\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.3070 - loss: 3.1101\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.3145 - loss: 3.0358\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 486ms/step - accuracy: 0.3286 - loss: 2.9592\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.3361 - loss: 2.8856\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.3510 - loss: 2.8096\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 506ms/step - accuracy: 0.3621 - loss: 2.7401\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.3718 - loss: 2.6664\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.3845 - loss: 2.6073\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 470ms/step - accuracy: 0.3890 - loss: 2.5360\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 508ms/step - accuracy: 0.4076 - loss: 2.4756\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.4165 - loss: 2.4108\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 383ms/step - accuracy: 0.4411 - loss: 2.3509\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.4523 - loss: 2.2980\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 501ms/step - accuracy: 0.4784 - loss: 2.2401\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 429ms/step - accuracy: 0.4955 - loss: 2.1861\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 442ms/step - accuracy: 0.5194 - loss: 2.1312\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - accuracy: 0.5306 - loss: 2.0682\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.5477 - loss: 2.0225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2f94e554b10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creazione del modello LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=seq_length-1))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Preparazione di y (one-hot encoding)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# Addestramento del modello\n",
    "model.fit(X, y, epochs=50, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217b0bf6-fa7b-4445-b7f6-6e5703a8f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funzione per generare del testo\n",
    "def generate_text(model, int_to_word, word_to_int, seed_text, seq_length, num_words):\n",
    "    # Inizializza il testo con il seed_text\n",
    "    result = seed_text\n",
    "    input_text = seed_text.lower().split()\n",
    "    \n",
    "    # Genera 'num_words' parole\n",
    "    for _ in range(num_words):\n",
    "        # Converte il testo in sequenza numerica\n",
    "        encoded = [word_to_int[word] for word in input_text if word in word_to_int]\n",
    "        \n",
    "        # Padding per la sequenza (poiché la sequenza di input deve avere una lunghezza fissa)\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length-1, padding='pre')\n",
    "        \n",
    "        # Predice la parola successiva\n",
    "        pred_probs = model.predict(encoded, verbose=0)\n",
    "        predicted_idx = np.argmax(pred_probs)\n",
    "        \n",
    "        # Converte l'indice predetto in parola\n",
    "        predicted_word = int_to_word[predicted_idx]\n",
    "        \n",
    "        # Aggiungi la parola predetta al testo\n",
    "        result += ' ' + predicted_word\n",
    "        \n",
    "        # Aggiungi la parola predetta alla sequenza di input per la prossima previsione\n",
    "        input_text.append(predicted_word)\n",
    "        input_text = input_text[1:]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb0e35f7-0580-4e88-9604-7bc1b0ac279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era una notte buia con la tuo partner con te . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo capoufficio . è il tuo\n"
     ]
    }
   ],
   "source": [
    "# Genera un testo nello stile dell'autore\n",
    "seed_text = \"era una notte buia\"  # Testo iniziale\n",
    "generated_text = generate_text(model, int_to_word, word_to_int, seed_text, seq_length, 100)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
